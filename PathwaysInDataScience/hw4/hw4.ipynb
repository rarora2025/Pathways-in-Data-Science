{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#This iS NOT the submission- submission is in Jay Warriors' Directory\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 4.7: $k$-nearest neighbors\n",
    "\n",
    "In this exercise, you will implement $k$-nearest neighbors from scratch. This means you're allowed to use whatever `numpy` routines you would like, **but you cannot use `sklearn.neighbors.KNeighborsClassifier`**.\n",
    "\n",
    "### Part (a): Implementation\n",
    "\n",
    "Complete the function `kNN()` below. The function takes in:\n",
    "\n",
    "* a 2D array of training vectors `X_train`, where `X_train[i]` denotes the ith vector and `X_train[i,j]` denotes the jth entry of the ith vector;\n",
    "* a collection of training labels `y_train` where `y_train[i]` is the correct label for `X_train[i]`;\n",
    "* a 2D array of unlabelled vectors `X_test`\n",
    "* a parameter `p` $\\geq 1$ that denotes the $\\ell^p$ norm to use for $k$-nearest neighbors\n",
    "* the number of neighbors `k`\n",
    "* a boolean `weighted`, where we compute weighted $k$-nearest neighbors if `weighted == True` and unweighted otherwise.\n",
    "\n",
    "The function returns the predicted labels for `X_test`.\n",
    "\n",
    "You are welcome (encouraged, in fact!) to write helper functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 2.0, 3.0]\n",
      "[2.0, 1.0, 0.0, 1.0, 2.0]\n",
      "[3.0, 2.0, 1.0, 0.0, 1.0]\n",
      "[4.0, 3.0, 2.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def eucledian(p1,p2):\n",
    "    dist = np.sqrt(np.sum((p1-p2)**2))\n",
    "    return dist\n",
    "\n",
    "def kNN(X_train, y_train, X_test, p, k, weighted):\n",
    "    for x in range(len(X_test)):\n",
    "        distances = []\n",
    "        for y in range(len(X_train)):\n",
    "            norm = eucledian(X_train[y], X_test[x])\n",
    "            distances.append(norm)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part (b): Testing it on the wine dataset\n",
    "\n",
    "Now you will test your classifier on the [wine dataset](https://archive.ics.uci.edu/ml/datasets/wine). Try out various methods for `k`, `p`, and `weighted` (note that you can approximate the $\\ell^\\infty$ norm by setting `p = 100` or some other large number). What works best? Plot your results and come up with some conclusions. What sort of performance do you get? You can measure the performance by simply computing what proportion of the testing data is labelled correctly; you can use `sklearn.metrics.accuracy_score` for this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# load the data...\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# split into training and testing sets with 100 training points and 50 testing points\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 50, random_state = 42)\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Report your results here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}